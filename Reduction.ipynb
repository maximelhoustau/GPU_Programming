{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Reduction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQNGZeSQo-CO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "6a6b1146-1e0a-49bc-d18d-a3138cfccd89"
      },
      "source": [
        "! pip install git+git://github.com/frehseg/nvcc4jupyter.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/frehseg/nvcc4jupyter.git\n",
            "  Cloning git://github.com/frehseg/nvcc4jupyter.git to /tmp/pip-req-build-snh787ni\n",
            "  Running command git clone -q git://github.com/frehseg/nvcc4jupyter.git /tmp/pip-req-build-snh787ni\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.1-cp36-none-any.whl size=2095 sha256=8932ca65a99430c238d8123e27d21a4e7b86072f32febe0672b1eb7e41cae2f7\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-qhyd4bxv/wheels/a4/a5/24/17a2b61f9a725a10155cc6fca753aae28436921df21fa16114\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-saRM-5pCsG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0KiWBMRNYcb",
        "colab_type": "text"
      },
      "source": [
        "## Divergent reduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4oDcqRANbK9",
        "colab_type": "text"
      },
      "source": [
        "This first reduction implement a vector reduction where only the pair threads are working together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEAR6WCCpEuo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "2d42bf43-135a-4f4c-82a7-181a338d0347"
      },
      "source": [
        "%%cu\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "#define THREAD_NB 1024\n",
        "#define SIZE 20\n",
        "\n",
        "#define CUDA_ERROR_CHECK\n",
        "\n",
        "#define CudaSafeCall( err ) __cudaSafeCall( err, __FILE__, __LINE__ )\n",
        "#define CudaCheckError()    __cudaCheckError( __FILE__, __LINE__ )\n",
        "\n",
        "/********************** kernel **************************/\n",
        "\n",
        "__global__ void reduction(int * tab_in, int * tab_out){\n",
        "  __shared__ int shared_mem[THREAD_NB];\n",
        "  \n",
        "  /*Each thread loads one element from tab_in memory to shared_memory*/\n",
        "  int thread_id = threadIdx.x;\n",
        "  int index = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  shared_mem[thread_id] = tab_in[index];\n",
        "  __syncthreads();\n",
        "\n",
        "  for(int i=1; i<blockDim.x; i*=2){\n",
        "      if(thread_id % (2*i) == 0){\n",
        "        shared_mem[thread_id] += shared_mem[thread_id+i];\n",
        "      } \n",
        "      __syncthreads(); \n",
        "  }\n",
        "\n",
        "  if (thread_id == 0){\n",
        "    tab_out[blockIdx.x] = shared_mem[0];\n",
        "  }\n",
        "}\n",
        "\n",
        "/********************** Host functions **************************/\n",
        "\n",
        "/*Initialization of array */\n",
        "void init_tab(int *tab, int value, int len){\n",
        "    for(int i=0; i<len; i++){\n",
        "        tab[i] = value;\n",
        "    }\n",
        "}\n",
        "\n",
        "/*For debugging purpose*/\n",
        "void affiche_tab(char *chaine, int *tab, int len){\n",
        "  int k;\n",
        "  int affiche = 10;\n",
        "  if(len<20){\n",
        "    affiche = len;\n",
        "  }\n",
        "  printf(\"\\nLes %i premiers de %s: \\n\", affiche, chaine);\n",
        "  for (k=0; k<affiche; k++) \n",
        "    printf(\"%i \",tab[k]);\n",
        "  printf(\"\\nLes %i derniers: \\n\", affiche);\n",
        "  for (k=len-affiche; k<len; k++) \n",
        "    printf(\"%i \",tab[k]);\n",
        "  printf(\"\\n\");\n",
        "}\n",
        "\n",
        "/*CUDA error checking */\n",
        "inline void __cudaSafeCall( cudaError err, const char *file, const int line )\n",
        "{\n",
        "#ifdef CUDA_ERROR_CHECK\n",
        "    if ( cudaSuccess != err )\n",
        "    {\n",
        "        fprintf( stderr, \"cudaSafeCall() failed at %s:%i : %s\\n\",\n",
        "                 file, line, cudaGetErrorString( err ) );\n",
        "        exit( -1 );\n",
        "    }\n",
        "#endif\n",
        "\n",
        "    return;\n",
        "}\n",
        "\n",
        "inline void __cudaCheckError( const char *file, const int line )\n",
        "{\n",
        "#ifdef CUDA_ERROR_CHECK\n",
        "    cudaError err = cudaGetLastError();\n",
        "    if ( cudaSuccess != err )\n",
        "    {\n",
        "        fprintf( stderr, \"cudaCheckError() failed at %s:%i : %s\\n\",\n",
        "                 file, line, cudaGetErrorString( err ) );\n",
        "        exit( -1 );\n",
        "    }\n",
        "\n",
        "    // More careful checking. However, this will affect performance.\n",
        "    // Comment away if needed.\n",
        "    err = cudaDeviceSynchronize();\n",
        "    if( cudaSuccess != err )\n",
        "    {\n",
        "        fprintf( stderr, \"cudaCheckError() with sync failed at %s:%i : %s\\n\",\n",
        "                 file, line, cudaGetErrorString( err ) );\n",
        "        exit( -1 );\n",
        "    }\n",
        "#endif\n",
        "\n",
        "    return;\n",
        "}\n",
        "\n",
        "/********************** main **************************/\n",
        "int main(void)\n",
        "{\n",
        "  int *tab_in, *tab_out, *gpu_tab_in, *gpu_tab_out;\n",
        "  float milliseconds = 0.0;\n",
        "  cudaEvent_t start, stop ;\n",
        "  int nIter = 100; \n",
        "  int dim_tab = THREAD_NB * SIZE;\n",
        "  int result = 0;\n",
        " \n",
        "  /*Memory allocation for CPU */\n",
        "  tab_in = (int*) malloc(dim_tab * sizeof(int));\n",
        "  tab_out = (int*) malloc(SIZE * sizeof(int));\n",
        "\n",
        "  /*Memory allocation for GPU */\n",
        "  cudaMalloc((void**) &gpu_tab_in, dim_tab* sizeof(int));\n",
        "  cudaMalloc((void**) &gpu_tab_out, SIZE * sizeof(int));  \n",
        " \n",
        "  /* Initialisation of tab_in and tab_out*/\n",
        "  init_tab(tab_in, 1, dim_tab);\n",
        "  init_tab(tab_out, 0, SIZE);\n",
        "  \n",
        "  /*Visualize the input arrays */ \n",
        "  affiche_tab(\"Tab_in\", tab_in, dim_tab);\n",
        "  affiche_tab(\"Tab_out\", tab_out, SIZE);\n",
        " \n",
        " /* Copy of tab_in and tab_out on GPU */\n",
        "  cudaMemcpy(gpu_tab_in, tab_in, dim_tab * sizeof(int), cudaMemcpyHostToDevice) ;\n",
        "  cudaMemcpy(gpu_tab_out, tab_out, SIZE * sizeof(int), cudaMemcpyHostToDevice) ;\n",
        "  \n",
        "  /* Let's compute the average computation time for the kernel to run */\n",
        "  for(int i=0; i<nIter; i++){\n",
        "    float tmp_timer = 0.0;\n",
        "    /* Start timer */\n",
        "    cudaEventCreate(&start) ; cudaEventCreate(&stop) ; cudaEventRecord(start) ;\n",
        "  \n",
        "    reduction<<<SIZE, THREAD_NB>>>(gpu_tab_in, gpu_tab_out);\n",
        "\n",
        "    /*Checking CUDA errors */\n",
        "    CudaCheckError();\n",
        "\n",
        "    cudaEventRecord(stop) ; cudaEventSynchronize(stop) ; //Guarantees that the event is finished\n",
        "    cudaEventElapsedTime(&tmp_timer, start, stop) ;\n",
        "    milliseconds += tmp_timer;\n",
        "  }\n",
        " \n",
        "  printf(\"\\nAverage time over %i iterations for the basic reduction to run: %f ms\\n\", nIter, milliseconds/nIter);\n",
        "  \n",
        "  /* Copie of tab_out on CPU */\n",
        "  cudaMemcpy(tab_out, gpu_tab_out, SIZE * sizeof(int), cudaMemcpyDeviceToHost) ;\n",
        "  \n",
        "  /*Visualize the output array */\n",
        "  affiche_tab(\"Reduction out\", tab_out, SIZE); \n",
        "\n",
        "  /*Do the actual reduction and check result*/\n",
        "  for(int j=0; j<SIZE; j++){\n",
        "      result += tab_out[j];\n",
        "  }\n",
        " \n",
        "  if(result != dim_tab)\n",
        "    printf(\"\\nThe reduction is wrong. Reduction value : %i\", result);\n",
        "  else\n",
        "    printf(\"\\nThe reduction is right. Reduction value : %i\", result);\n",
        " \n",
        "\n",
        "  /* Free GPU memory*/ \n",
        "  cudaFree(gpu_tab_in);\n",
        "  cudaFree(gpu_tab_out);\n",
        "\n",
        "  /* Free CPU memory*/\n",
        "  free(tab_in);\n",
        "  free(tab_out);\n",
        "}"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Les 10 premiers de Tab_in: \n",
            "1 1 1 1 1 1 1 1 1 1 \n",
            "Les 10 derniers: \n",
            "1 1 1 1 1 1 1 1 1 1 \n",
            "\n",
            "Les 10 premiers de Tab_out: \n",
            "0 0 0 0 0 0 0 0 0 0 \n",
            "Les 10 derniers: \n",
            "0 0 0 0 0 0 0 0 0 0 \n",
            "\n",
            "Average time over 100 iterations for the basic reduction to run: 0.022144 ms\n",
            "\n",
            "Les 10 premiers de Reduction out: \n",
            "1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 \n",
            "Les 10 derniers: \n",
            "1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 \n",
            "\n",
            "The reduction is right. Reduction value : 20480\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-vyVRhqTTM2",
        "colab_type": "text"
      },
      "source": [
        "## Parallel reduction with bank conflicts\n",
        "\n",
        "This second version implements a reduction where every threads are working together."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqxymG5DTqsb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "ce4fb625-bb7f-49f8-f025-24944f86fa49"
      },
      "source": [
        "%%cu\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "#define THREAD_NB 1024\n",
        "#define SIZE 20\n",
        "\n",
        "#define CUDA_ERROR_CHECK\n",
        "\n",
        "#define CudaSafeCall( err ) __cudaSafeCall( err, __FILE__, __LINE__ )\n",
        "#define CudaCheckError()    __cudaCheckError( __FILE__, __LINE__ )\n",
        "\n",
        "/********************** kernel **************************/\n",
        "\n",
        "__global__ void reduction(int * tab_in, int * tab_out){\n",
        "  __shared__ int shared_mem[THREAD_NB];\n",
        "  \n",
        "  /*Each thread loads one element from tab_in memory to shared_memory*/\n",
        "  int thread_id = threadIdx.x;\n",
        "  int index_th = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  shared_mem[thread_id] = tab_in[index_th];\n",
        "  __syncthreads();\n",
        "\n",
        "  for (int i=1; i < blockDim.x; i*= 2) {\n",
        "    int index = 2 * i * thread_id;\n",
        "    if (index < blockDim.x) {\n",
        "      shared_mem[index] += shared_mem[index + i];\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "\n",
        "  if (thread_id == 0){\n",
        "    tab_out[blockIdx.x] = shared_mem[0];\n",
        "  }\n",
        "}\n",
        "\n",
        "/********************** Host functions **************************/\n",
        "\n",
        "/*Initialization of array */\n",
        "void init_tab(int *tab, int value, int len){\n",
        "    for(int i=0; i<len; i++){\n",
        "        tab[i] = value;\n",
        "    }\n",
        "}\n",
        "\n",
        "/*For debugging purpose*/\n",
        "void affiche_tab(char *chaine, int *tab, int len){\n",
        "  int k;\n",
        "  int affiche = 10;\n",
        "  if(len<20){\n",
        "    affiche = len;\n",
        "  }\n",
        "  printf(\"\\nLes %i premiers de %s: \\n\", affiche, chaine);\n",
        "  for (k=0; k<affiche; k++) \n",
        "    printf(\"%i \",tab[k]);\n",
        "  printf(\"\\nLes %i derniers: \\n\", affiche);\n",
        "  for (k=len-affiche; k<len; k++) \n",
        "    printf(\"%i \",tab[k]);\n",
        "  printf(\"\\n\");\n",
        "}\n",
        "\n",
        "/*CUDA error checking */\n",
        "inline void __cudaSafeCall( cudaError err, const char *file, const int line )\n",
        "{\n",
        "#ifdef CUDA_ERROR_CHECK\n",
        "    if ( cudaSuccess != err )\n",
        "    {\n",
        "        fprintf( stderr, \"cudaSafeCall() failed at %s:%i : %s\\n\",\n",
        "                 file, line, cudaGetErrorString( err ) );\n",
        "        exit( -1 );\n",
        "    }\n",
        "#endif\n",
        "\n",
        "    return;\n",
        "}\n",
        "\n",
        "inline void __cudaCheckError( const char *file, const int line )\n",
        "{\n",
        "#ifdef CUDA_ERROR_CHECK\n",
        "    cudaError err = cudaGetLastError();\n",
        "    if ( cudaSuccess != err )\n",
        "    {\n",
        "        fprintf( stderr, \"cudaCheckError() failed at %s:%i : %s\\n\",\n",
        "                 file, line, cudaGetErrorString( err ) );\n",
        "        exit( -1 );\n",
        "    }\n",
        "\n",
        "    // More careful checking. However, this will affect performance.\n",
        "    // Comment away if needed.\n",
        "    err = cudaDeviceSynchronize();\n",
        "    if( cudaSuccess != err )\n",
        "    {\n",
        "        fprintf( stderr, \"cudaCheckError() with sync failed at %s:%i : %s\\n\",\n",
        "                 file, line, cudaGetErrorString( err ) );\n",
        "        exit( -1 );\n",
        "    }\n",
        "#endif\n",
        "\n",
        "    return;\n",
        "}\n",
        "\n",
        "/********************** main **************************/\n",
        "int main(void)\n",
        "{\n",
        "  int *tab_in, *tab_out, *gpu_tab_in, *gpu_tab_out;\n",
        "  float milliseconds = 0.0;\n",
        "  cudaEvent_t start, stop ;\n",
        "  int nIter = 100; \n",
        "  int dim_tab = THREAD_NB * SIZE;\n",
        "  int result = 0;\n",
        " \n",
        "  /*Memory allocation for CPU */\n",
        "  tab_in = (int*) malloc(dim_tab * sizeof(int));\n",
        "  tab_out = (int*) malloc(SIZE * sizeof(int));\n",
        "\n",
        "  /*Memory allocation for GPU */\n",
        "  cudaMalloc((void**) &gpu_tab_in, dim_tab* sizeof(int));\n",
        "  cudaMalloc((void**) &gpu_tab_out, SIZE * sizeof(int));  \n",
        " \n",
        "  /* Initialisation of tab_in and tab_out*/\n",
        "  init_tab(tab_in, 1, dim_tab);\n",
        "  init_tab(tab_out, 0, SIZE);\n",
        "  \n",
        "  /*Visualize the input arrays */ \n",
        "  affiche_tab(\"Tab_in\", tab_in, dim_tab);\n",
        "  affiche_tab(\"Tab_out\", tab_out, SIZE);\n",
        " \n",
        " /* Copy of tab_in and tab_out on GPU */\n",
        "  cudaMemcpy(gpu_tab_in, tab_in, dim_tab * sizeof(int), cudaMemcpyHostToDevice) ;\n",
        "  cudaMemcpy(gpu_tab_out, tab_out, SIZE * sizeof(int), cudaMemcpyHostToDevice) ;\n",
        "  \n",
        "  /* Let's compute the average computation time for the kernel to run */\n",
        "  for(int i=0; i<nIter; i++){\n",
        "    float tmp_timer = 0.0;\n",
        "    /* Start timer */\n",
        "    cudaEventCreate(&start) ; cudaEventCreate(&stop) ; cudaEventRecord(start) ;\n",
        "  \n",
        "    reduction<<<SIZE, THREAD_NB>>>(gpu_tab_in, gpu_tab_out);\n",
        "\n",
        "    /*Checking CUDA errors */\n",
        "    CudaCheckError();\n",
        "\n",
        "    cudaEventRecord(stop) ; cudaEventSynchronize(stop) ; //Guarantees that the event is finished\n",
        "    cudaEventElapsedTime(&tmp_timer, start, stop) ;\n",
        "    milliseconds += tmp_timer;\n",
        "  }\n",
        " \n",
        "  printf(\"\\nAverage time over %i iterations for the parallel reduction (with Bank conflicts) to run: %f ms\\n\", nIter, milliseconds/nIter);\n",
        "  \n",
        "  /* Copie of tab_out on CPU */\n",
        "  cudaMemcpy(tab_out, gpu_tab_out, SIZE * sizeof(int), cudaMemcpyDeviceToHost) ;\n",
        "  \n",
        "  /*Visualize the output array */\n",
        "  affiche_tab(\"Reduction out\", tab_out, SIZE); \n",
        "\n",
        "  /*Do the actual reduction and check result*/\n",
        "  for(int j=0; j<SIZE; j++){\n",
        "      result += tab_out[j];\n",
        "  }\n",
        " \n",
        "  if(result != dim_tab)\n",
        "    printf(\"\\nThe reduction is wrong. Reduction value : %i\", result);\n",
        "  else\n",
        "    printf(\"\\nThe reduction is right. Reduction value : %i\", result);\n",
        " \n",
        "\n",
        "  /* Free GPU memory*/ \n",
        "  cudaFree(gpu_tab_in);\n",
        "  cudaFree(gpu_tab_out);\n",
        "\n",
        "  /* Free CPU memory*/\n",
        "  free(tab_in);\n",
        "  free(tab_out);\n",
        "}"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Les 10 premiers de Tab_in: \n",
            "1 1 1 1 1 1 1 1 1 1 \n",
            "Les 10 derniers: \n",
            "1 1 1 1 1 1 1 1 1 1 \n",
            "\n",
            "Les 10 premiers de Tab_out: \n",
            "0 0 0 0 0 0 0 0 0 0 \n",
            "Les 10 derniers: \n",
            "0 0 0 0 0 0 0 0 0 0 \n",
            "\n",
            "Average time over 100 iterations for the parallel reduction (with Bank conflicts) to run: 0.016999 ms\n",
            "\n",
            "Les 10 premiers de Reduction out: \n",
            "1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 \n",
            "Les 10 derniers: \n",
            "1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 \n",
            "\n",
            "The reduction is right. Reduction value : 20480\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVhrVJRiVux9",
        "colab_type": "text"
      },
      "source": [
        "## Parallel reduction without without bank conflicts"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aU7cWUtHV1IA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        },
        "outputId": "b92d838f-7c82-4aca-8cf9-29e32cad1896"
      },
      "source": [
        "%%cu\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "\n",
        "#define THREAD_NB 1024\n",
        "#define SIZE 20\n",
        "\n",
        "#define CUDA_ERROR_CHECK\n",
        "\n",
        "#define CudaSafeCall( err ) __cudaSafeCall( err, __FILE__, __LINE__ )\n",
        "#define CudaCheckError()    __cudaCheckError( __FILE__, __LINE__ )\n",
        "\n",
        "/********************** kernel **************************/\n",
        "\n",
        "__global__ void reduction(int * tab_in, int * tab_out){\n",
        "  __shared__ int shared_mem[THREAD_NB];\n",
        "  \n",
        "  /*Each thread loads one element from tab_in memory to shared_memory*/\n",
        "  int thread_id = threadIdx.x;\n",
        "  int index_th = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "  shared_mem[thread_id] = tab_in[index_th];\n",
        "  __syncthreads();\n",
        "\n",
        "  for (int i=blockDim.x/2; i>0; i>>=1) {\n",
        "    if (thread_id < i) {\n",
        "      shared_mem[thread_id] += shared_mem[thread_id + i];\n",
        "    }\n",
        "    __syncthreads();\n",
        "  }\n",
        "\n",
        "  if (thread_id == 0){\n",
        "    tab_out[blockIdx.x] = shared_mem[0];\n",
        "  }\n",
        "}\n",
        "\n",
        "/********************** Host functions **************************/\n",
        "\n",
        "/*Initialization of array */\n",
        "void init_tab(int *tab, int value, int len){\n",
        "    for(int i=0; i<len; i++){\n",
        "        tab[i] = value;\n",
        "    }\n",
        "}\n",
        "\n",
        "/*For debugging purpose*/\n",
        "void affiche_tab(char *chaine, int *tab, int len){\n",
        "  int k;\n",
        "  int affiche = 10;\n",
        "  if(len<20){\n",
        "    affiche = len;\n",
        "  }\n",
        "  printf(\"\\nLes %i premiers de %s: \\n\", affiche, chaine);\n",
        "  for (k=0; k<affiche; k++) \n",
        "    printf(\"%i \",tab[k]);\n",
        "  printf(\"\\nLes %i derniers: \\n\", affiche);\n",
        "  for (k=len-affiche; k<len; k++) \n",
        "    printf(\"%i \",tab[k]);\n",
        "  printf(\"\\n\");\n",
        "}\n",
        "\n",
        "/*CUDA error checking */\n",
        "inline void __cudaSafeCall( cudaError err, const char *file, const int line )\n",
        "{\n",
        "#ifdef CUDA_ERROR_CHECK\n",
        "    if ( cudaSuccess != err )\n",
        "    {\n",
        "        fprintf( stderr, \"cudaSafeCall() failed at %s:%i : %s\\n\",\n",
        "                 file, line, cudaGetErrorString( err ) );\n",
        "        exit( -1 );\n",
        "    }\n",
        "#endif\n",
        "\n",
        "    return;\n",
        "}\n",
        "\n",
        "inline void __cudaCheckError( const char *file, const int line )\n",
        "{\n",
        "#ifdef CUDA_ERROR_CHECK\n",
        "    cudaError err = cudaGetLastError();\n",
        "    if ( cudaSuccess != err )\n",
        "    {\n",
        "        fprintf( stderr, \"cudaCheckError() failed at %s:%i : %s\\n\",\n",
        "                 file, line, cudaGetErrorString( err ) );\n",
        "        exit( -1 );\n",
        "    }\n",
        "\n",
        "    // More careful checking. However, this will affect performance.\n",
        "    // Comment away if needed.\n",
        "    err = cudaDeviceSynchronize();\n",
        "    if( cudaSuccess != err )\n",
        "    {\n",
        "        fprintf( stderr, \"cudaCheckError() with sync failed at %s:%i : %s\\n\",\n",
        "                 file, line, cudaGetErrorString( err ) );\n",
        "        exit( -1 );\n",
        "    }\n",
        "#endif\n",
        "\n",
        "    return;\n",
        "}\n",
        "\n",
        "/********************** main **************************/\n",
        "int main(void)\n",
        "{\n",
        "  int *tab_in, *tab_out, *gpu_tab_in, *gpu_tab_out;\n",
        "  float milliseconds = 0.0;\n",
        "  cudaEvent_t start, stop ;\n",
        "  int nIter = 100; \n",
        "  int dim_tab = THREAD_NB * SIZE;\n",
        "  int result = 0;\n",
        " \n",
        "  /*Memory allocation for CPU */\n",
        "  tab_in = (int*) malloc(dim_tab * sizeof(int));\n",
        "  tab_out = (int*) malloc(SIZE * sizeof(int));\n",
        "\n",
        "  /*Memory allocation for GPU */\n",
        "  cudaMalloc((void**) &gpu_tab_in, dim_tab* sizeof(int));\n",
        "  cudaMalloc((void**) &gpu_tab_out, SIZE * sizeof(int));  \n",
        " \n",
        "  /* Initialisation of tab_in and tab_out*/\n",
        "  init_tab(tab_in, 1, dim_tab);\n",
        "  init_tab(tab_out, 0, SIZE);\n",
        "  \n",
        "  /*Visualize the input arrays */ \n",
        "  affiche_tab(\"Tab_in\", tab_in, dim_tab);\n",
        "  affiche_tab(\"Tab_out\", tab_out, SIZE);\n",
        " \n",
        " /* Copy of tab_in and tab_out on GPU */\n",
        "  cudaMemcpy(gpu_tab_in, tab_in, dim_tab * sizeof(int), cudaMemcpyHostToDevice) ;\n",
        "  cudaMemcpy(gpu_tab_out, tab_out, SIZE * sizeof(int), cudaMemcpyHostToDevice) ;\n",
        "  \n",
        "  /* Let's compute the average computation time for the kernel to run */\n",
        "  for(int i=0; i<nIter; i++){\n",
        "    float tmp_timer = 0.0;\n",
        "    /* Start timer */\n",
        "    cudaEventCreate(&start) ; cudaEventCreate(&stop) ; cudaEventRecord(start) ;\n",
        "  \n",
        "    reduction<<<SIZE, THREAD_NB>>>(gpu_tab_in, gpu_tab_out);\n",
        "\n",
        "    /*Checking CUDA errors */\n",
        "    CudaCheckError();\n",
        "\n",
        "    cudaEventRecord(stop) ; cudaEventSynchronize(stop) ; //Guarantees that the event is finished\n",
        "    cudaEventElapsedTime(&tmp_timer, start, stop) ;\n",
        "    milliseconds += tmp_timer;\n",
        "  }\n",
        " \n",
        "  printf(\"\\nAverage time over %i iterations for the parallel reduction (without Bank conflicts) to run: %f ms\\n\", nIter, milliseconds/nIter);\n",
        "  \n",
        "  /* Copie of tab_out on CPU */\n",
        "  cudaMemcpy(tab_out, gpu_tab_out, SIZE * sizeof(int), cudaMemcpyDeviceToHost) ;\n",
        "  \n",
        "  /*Visualize the output array */\n",
        "  affiche_tab(\"Reduction out\", tab_out, SIZE); \n",
        "\n",
        "  /*Do the actual reduction and check result*/\n",
        "  for(int j=0; j<SIZE; j++){\n",
        "      result += tab_out[j];\n",
        "  }\n",
        " \n",
        "  if(result != dim_tab)\n",
        "    printf(\"\\nThe reduction is wrong. Reduction value : %i\", result);\n",
        "  else\n",
        "    printf(\"\\nThe reduction is right. Reduction value : %i\", result);\n",
        " \n",
        "\n",
        "  /* Free GPU memory*/ \n",
        "  cudaFree(gpu_tab_in);\n",
        "  cudaFree(gpu_tab_out);\n",
        "\n",
        "  /* Free CPU memory*/\n",
        "  free(tab_in);\n",
        "  free(tab_out);\n",
        "}"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Les 10 premiers de Tab_in: \n",
            "1 1 1 1 1 1 1 1 1 1 \n",
            "Les 10 derniers: \n",
            "1 1 1 1 1 1 1 1 1 1 \n",
            "\n",
            "Les 10 premiers de Tab_out: \n",
            "0 0 0 0 0 0 0 0 0 0 \n",
            "Les 10 derniers: \n",
            "0 0 0 0 0 0 0 0 0 0 \n",
            "\n",
            "Average time over 100 iterations for the parallel reduction (without Bank conflicts) to run: 0.016377 ms\n",
            "\n",
            "Les 10 premiers de Reduction out: \n",
            "1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 \n",
            "Les 10 derniers: \n",
            "1024 1024 1024 1024 1024 1024 1024 1024 1024 1024 \n",
            "\n",
            "The reduction is right. Reduction value : 20480\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C35iYsD2Widm",
        "colab_type": "text"
      },
      "source": [
        "## Thrust version of reduction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZI2_CE1WlTM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "5b9b682b-4db0-480b-99a6-6e627d59014c"
      },
      "source": [
        "%%cu\n",
        "#include <thrust/host_vector.h>\n",
        "#include <thrust/device_vector.h>\n",
        "#include <thrust/generate.h>\n",
        "#include <thrust/reduce.h>\n",
        "#include <thrust/functional.h>\n",
        "#include <algorithm>\n",
        "#include <cstdlib>\n",
        "\n",
        "#define THREAD_NB 1024\n",
        "#define SIZE 20\n",
        "\n",
        "int f()\n",
        "{ \n",
        "    return 1;\n",
        "}\n",
        "/********************** main **************************/\n",
        "int main(void)\n",
        "{\n",
        "  double milliseconds = 0.0;\n",
        "  cudaEvent_t start, stop ;\n",
        "  int nIter = 100;\n",
        "  int dim_tab = THREAD_NB * SIZE;\n",
        "  int result = 0;\n",
        "  \n",
        "  // generate input data\n",
        "  thrust::host_vector<int> tab_in(dim_tab);\n",
        "  std::generate(tab_in.begin(), tab_in.end(), f);\n",
        "\n",
        "  // transfer to device and compute sum\n",
        "  thrust::device_vector<int> tab_out = tab_in;\n",
        "  cudaDeviceSynchronize();\n",
        "\n",
        "  /* Let's compute the average computation time for the kernel to run */\n",
        "  for(int i=0; i<nIter; i++){\n",
        "    float tmp_timer = 0.0;\n",
        "    /* Start timer */\n",
        "    cudaEventCreate(&start) ; cudaEventCreate(&stop) ; cudaEventRecord(start) ;\n",
        "\n",
        "    result = thrust::reduce(tab_out.begin(), tab_out.end(), 0, thrust::plus<int>());\n",
        "    cudaDeviceSynchronize();\n",
        "\n",
        "    cudaEventRecord(stop) ; cudaEventSynchronize(stop) ; //Guarantees that the event is finished\n",
        "    cudaEventElapsedTime(&tmp_timer, start, stop) ;\n",
        "    milliseconds += tmp_timer;\n",
        "  }\n",
        " \n",
        "  printf(\"\\nAverage time over %i iterations for the Thrust version of parallel reduction to run: %f ms\\n\", nIter, milliseconds/nIter);\n",
        "\n",
        "  //Check result\n",
        "  if(result != dim_tab)\n",
        "    printf(\"\\nThe reduction is wrong. Reduction value : %i\", result);\n",
        "  else\n",
        "    printf(\"\\nThe reduction is right. Reduction value : %i\", result);\n",
        " \n",
        "  return 0;\n",
        "}"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Average time over 100 iterations for the Thrust version of parallel reduction to run: 0.043295 ms\n",
            "\n",
            "The reduction is right. Reduction value : 20480\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjC0F_C6TZoW",
        "colab_type": "text"
      },
      "source": [
        "## Comparison of results and analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jt4doTDaTreJ",
        "colab_type": "text"
      },
      "source": [
        " \n",
        " Here is the summary of the average computation time of the different reduction method : \n",
        "\n",
        "Reduction method  | Divergent | Parallel/Bank conflicts | Parallel/No Bank conflicts | Thrust version\n",
        "--- | --- | --- | --- | ---\n",
        "Time (ms) | 0.022 | 0.017 | 0.016 | 0.043"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZcYhYue3MV1",
        "colab_type": "text"
      },
      "source": [
        "* The **divergent** version of reduction only make the paired thread to work together, so if we want to compute the sum of a n lengthed array, only n/2 thread will work. That is why this method is the slowest one.\n",
        "\n",
        "* The **first parallel** version of reduction is a version with bank conflicts. In order to make all threads work together, we use strided index as well as non-divergent branch. This is why the the parallel reduction is quicker than the divergent one. However, as different threads are trying to read into the same region of memory (called banks) at the same time, ang given that a bank can only retrieve a cell memory per clock cycle, we cause bank conflicts. If n threads try to access n memory cells into the same bank, with this version we achieve that in n clock cycles. This is a limitation that we are solve in the second version of the parallel reduction.\n",
        "\n",
        "* The **second parallel** version of reduction is implemented without any bank conflict, meaning that we can access n memory celles in only one clock cycle. This is achevied by using a reversed loop and thread-id based indexing. This version is the most optimized version of reduction and so the quickest.\n",
        "\n",
        "* We also implemented a **version with the Thrust library**, that does not need particular code wirting. We just build the arrays with the C++ built-in functions, and then we launch the reduction with the reduce function of Thrust. This library handles GPU without the need to write kernel functions. However, this function has the worst average computation time."
      ]
    }
  ]
}