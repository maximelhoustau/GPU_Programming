{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Matrix-Multiplication.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "S5GpOqmiHszG",
        "uSIQI2yJH9t4",
        "cDYPhswTIHao",
        "FxMRtRX5IPl1",
        "cPsb7v8GIPof",
        "cOxvzphXFvt6",
        "TmfA56k6GbSZ",
        "GwKRuVpxP4Ci"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWUsiAohd0P6",
        "colab_type": "code",
        "outputId": "8429aecc-e6d7-4aad-d120-370a3248b60c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        }
      },
      "source": [
        "! pip install git+git://github.com/frehseg/nvcc4jupyter.git"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+git://github.com/frehseg/nvcc4jupyter.git\n",
            "  Cloning git://github.com/frehseg/nvcc4jupyter.git to /tmp/pip-req-build-uw3pn5hk\n",
            "  Running command git clone -q git://github.com/frehseg/nvcc4jupyter.git /tmp/pip-req-build-uw3pn5hk\n",
            "Building wheels for collected packages: NVCCPlugin\n",
            "  Building wheel for NVCCPlugin (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for NVCCPlugin: filename=NVCCPlugin-0.0.1-cp36-none-any.whl size=2095 sha256=cd9ce27ebcf6138adc9de45e51b2373c40f6e7ec717ac999e5956ca6a2dd40d8\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-aap2jdfv/wheels/a4/a5/24/17a2b61f9a725a10155cc6fca753aae28436921df21fa16114\n",
            "Successfully built NVCCPlugin\n",
            "Installing collected packages: NVCCPlugin\n",
            "Successfully installed NVCCPlugin-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1EMybILd1VU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext nvcc_plugin"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBeP58I-Fa3p",
        "colab_type": "text"
      },
      "source": [
        "## Basic matrix multiplication (non tiled algorithm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5GpOqmiHszG",
        "colab_type": "text"
      },
      "source": [
        "### TILE_WIDTH = 32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOmmgILtd1gT",
        "colab_type": "code",
        "outputId": "32fb08bd-d18f-4fb9-e2ba-fff108b23484",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "%%cu\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "#include <cublas_v2.h>\n",
        "\n",
        "#define TILE_WIDTH 32\n",
        "#define SIZE 20\n",
        "/********************** kernel **************************/\n",
        "__global__\n",
        "void matmul_basique(float *A, float *B, float *C, int nb_ColA, int nb_ColB, int nb_LigneA, int nb_LigneB)\n",
        "{\n",
        "  int row = blockIdx.y*blockDim.y+threadIdx.y;\n",
        "  int col = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "  float product_val = 0;\n",
        "  if(row < nb_ColA && col < nb_LigneA){\n",
        "    for(int k=0; k<nb_ColA;k++) {\n",
        "      product_val += A[row*nb_ColA+k]*B[k*nb_ColA+col];\n",
        "    }\n",
        "    C[row*nb_ColA+col] = product_val;\n",
        "  }\n",
        "}\n",
        "\n",
        "/********************** Host functions **************************/\n",
        "\n",
        "/*For debugging purpose*/\n",
        "void affiche_tab(char *chaine, float *tab, int len){\n",
        "   int k;\n",
        "   printf(\"\\nLes 10 premiers de %s: \\n\",chaine);\n",
        "   for (k=0; k<10; k++) \n",
        "      printf(\"%.2f \",tab[k]);\n",
        "   printf(\"\\nLes 10 derniers: \\n\");\n",
        "   for (k=0; k<len; k++){\n",
        "       if(tab[k] == 0){\n",
        "           printf(\"%i \", k);\n",
        "           break;\n",
        "       }\n",
        "   } \n",
        "   printf(\"\\n\");\n",
        "}\n",
        "\n",
        "/********************** main **************************/\n",
        "int main(void)\n",
        "{\n",
        "  float *A, *B, *C, *gpu_A, *gpu_B, *gpu_C;\n",
        "  int nbLigneA, nbLigneB, nbColA, nbColB;\n",
        "  float milliseconds = 0.0;\n",
        "  cudaEvent_t start, stop ;\n",
        "  int nIter = 100;\n",
        "  \n",
        "  nbLigneA = TILE_WIDTH * SIZE;\n",
        "  nbLigneB = TILE_WIDTH * SIZE;\n",
        "  nbColA = TILE_WIDTH * SIZE;\n",
        "  nbColB = TILE_WIDTH * SIZE;\n",
        "\n",
        "  dim3 DimGrid(SIZE, SIZE, 1);\n",
        "  dim3 DimBlock(TILE_WIDTH, TILE_WIDTH, 1);\n",
        " \n",
        "  A = (float*) malloc(nbLigneA * nbColA * sizeof(float));\n",
        "  B = (float*) malloc(nbLigneB * nbColB * sizeof(float));\n",
        "  C = (float*) malloc(nbLigneA * nbColB * sizeof(float));\n",
        "\n",
        "  /*Allocation de l'espace pour le GPU */\n",
        "  cudaMalloc((void**) &gpu_A, nbLigneA * nbColA * sizeof(float));\n",
        "  cudaMalloc((void**) &gpu_B, nbLigneB * nbColB * sizeof(float));\n",
        "  cudaMalloc((void**) &gpu_C, nbLigneA * nbColB * sizeof(float));  \n",
        " \n",
        "  /* Initialisation de A et B*/\n",
        "  for (int i = 0; i < nbLigneA * nbColA; i++) {\n",
        "    A[i] = 1.0;\n",
        "  }\n",
        "\n",
        "  for (int i = 0; i < nbLigneB * nbColB; i++) {\n",
        "    B[i] = 2.0;\n",
        "  }\n",
        "\n",
        " /* Copie de gpu_A et gpu_B sur le GPU */\n",
        "  cudaMemcpy(gpu_A, A, nbLigneA * nbColA * sizeof(float), cudaMemcpyHostToDevice) ;\n",
        "  cudaMemcpy(gpu_B, B, nbLigneB * nbColB * sizeof(float), cudaMemcpyHostToDevice) ;\n",
        "  \n",
        "/* Moyenne du temps d'exécution de la multiplication de matrice basique */\n",
        "  for(int i=0; i<nIter; i++){\n",
        "    float tmp_timer = 0.0;\n",
        "    /* Lancement du kernel avec mesure du temps */\n",
        "    cudaEventCreate(&start) ; cudaEventCreate(&stop) ;\n",
        "    cudaEventRecord(start) ;\n",
        "  \n",
        "    matmul_basique<<<DimGrid, DimBlock>>>(gpu_A, gpu_B, gpu_C, nbLigneA, nbLigneB, nbColA, nbColB);\n",
        "  \n",
        "    cudaEventRecord(stop) ;\n",
        "    cudaEventSynchronize(stop) ; //Garantit que l’événement s’est exécuté \n",
        "    cudaEventElapsedTime(&tmp_timer, start, stop) ;\n",
        "    milliseconds += tmp_timer;\n",
        "  }\n",
        " \n",
        "  printf(\"Average time over %i iterations for basic matrix mutliplication with TILE_WIDTH = %i : %f ms\", nIter, TILE_WIDTH, milliseconds/nIter);\n",
        "  \n",
        "  /* Copie de gpu_C du GPU sur le CPU */\n",
        "  cudaMemcpy(C, gpu_C, nbLigneA * nbColB * sizeof(float), cudaMemcpyDeviceToHost) ;\n",
        " \n",
        "  /* Vérification du résultat*/\n",
        "  float maxError = 0.0f;\n",
        "  for (int i = 0; i < nbLigneA * nbColB; i++){\n",
        "      maxError = max(maxError, abs(C[i]- 2*nbLigneB));\n",
        "  }\n",
        "  printf(\"\\nMax error: %f\\n\", maxError);\n",
        " \n",
        "  if(maxError == 0)\n",
        "    printf(\"No errors in the computations of the multiplication !\");\n",
        "\n",
        "  /* Libération de la mémoire sur le GPU*/ \n",
        "  cudaFree(gpu_A);\n",
        "  cudaFree(gpu_B);\n",
        "  cudaFree(gpu_C);\n",
        "\n",
        "  /* Libération de la mémoire sur le CPU*/\n",
        "  free(A);\n",
        "  free(B);\n",
        "  free(C);\n",
        "}\n"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average time over 100 iterations for basic matrix mutliplication with TILE_WIDTH = 32 : 1.547700 ms\n",
            "Max error: 0.000000\n",
            "No errors in the computations of the multiplication !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSIQI2yJH9t4",
        "colab_type": "text"
      },
      "source": [
        "### TILE_WIDTH = 16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wfl8uH83DtpQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "31f44a78-06c1-4602-b27b-302974a8341d"
      },
      "source": [
        "%%cu\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "#include <cublas_v2.h>\n",
        "\n",
        "#define TILE_WIDTH 16\n",
        "#define SIZE 20\n",
        "/********************** kernel **************************/\n",
        "__global__\n",
        "void matmul_basique(float *A, float *B, float *C, int nb_ColA, int nb_ColB, int nb_LigneA, int nb_LigneB)\n",
        "{\n",
        "  int row = blockIdx.y*blockDim.y+threadIdx.y;\n",
        "  int col = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "  float product_val = 0;\n",
        "  if(row < nb_ColA && col < nb_LigneA){\n",
        "    for(int k=0; k<nb_ColA;k++) {\n",
        "      product_val += A[row*nb_ColA+k]*B[k*nb_ColA+col];\n",
        "    }\n",
        "    C[row*nb_ColA+col] = product_val;\n",
        "  }\n",
        "}\n",
        "\n",
        "/********************** Host functions **************************/\n",
        "\n",
        "/*For debugging purpose*/\n",
        "void affiche_tab(char *chaine, float *tab, int len){\n",
        "   int k;\n",
        "   printf(\"\\nLes 10 premiers de %s: \\n\",chaine);\n",
        "   for (k=0; k<10; k++) \n",
        "      printf(\"%.2f \",tab[k]);\n",
        "   printf(\"\\nLes 10 derniers: \\n\");\n",
        "   for (k=0; k<len; k++){\n",
        "       if(tab[k] == 0){\n",
        "           printf(\"%i \", k);\n",
        "           break;\n",
        "       }\n",
        "   } \n",
        "   printf(\"\\n\");\n",
        "}\n",
        "\n",
        "/********************** main **************************/\n",
        "int main(void)\n",
        "{\n",
        "  float *A, *B, *C, *gpu_A, *gpu_B, *gpu_C;\n",
        "  int nbLigneA, nbLigneB, nbColA, nbColB;\n",
        "  float milliseconds = 0.0;\n",
        "  cudaEvent_t start, stop ;\n",
        "  int nIter = 100;\n",
        "  \n",
        "  nbLigneA = TILE_WIDTH * SIZE;\n",
        "  nbLigneB = TILE_WIDTH * SIZE;\n",
        "  nbColA = TILE_WIDTH * SIZE;\n",
        "  nbColB = TILE_WIDTH * SIZE;\n",
        "\n",
        "  dim3 DimGrid(SIZE, SIZE, 1);\n",
        "  dim3 DimBlock(TILE_WIDTH, TILE_WIDTH, 1);\n",
        " \n",
        "  A = (float*) malloc(nbLigneA * nbColA * sizeof(float));\n",
        "  B = (float*) malloc(nbLigneB * nbColB * sizeof(float));\n",
        "  C = (float*) malloc(nbLigneA * nbColB * sizeof(float));\n",
        "\n",
        "  /*Allocation de l'espace pour le GPU */\n",
        "  cudaMalloc((void**) &gpu_A, nbLigneA * nbColA * sizeof(float));\n",
        "  cudaMalloc((void**) &gpu_B, nbLigneB * nbColB * sizeof(float));\n",
        "  cudaMalloc((void**) &gpu_C, nbLigneA * nbColB * sizeof(float));  \n",
        " \n",
        "  /* Initialisation de A et B*/\n",
        "  for (int i = 0; i < nbLigneA * nbColA; i++) {\n",
        "    A[i] = 1.0;\n",
        "  }\n",
        "\n",
        "  for (int i = 0; i < nbLigneB * nbColB; i++) {\n",
        "    B[i] = 2.0;\n",
        "  }\n",
        "\n",
        " /* Copie de gpu_A et gpu_B sur le GPU */\n",
        "  cudaMemcpy(gpu_A, A, nbLigneA * nbColA * sizeof(float), cudaMemcpyHostToDevice) ;\n",
        "  cudaMemcpy(gpu_B, B, nbLigneB * nbColB * sizeof(float), cudaMemcpyHostToDevice) ;\n",
        "  \n",
        "/* Moyenne du temps d'exécution de la multiplication de matrice basique */\n",
        "  for(int i=0; i<nIter; i++){\n",
        "    float tmp_timer = 0.0;\n",
        "    /* Lancement du kernel avec mesure du temps */\n",
        "    cudaEventCreate(&start) ; cudaEventCreate(&stop) ;\n",
        "    cudaEventRecord(start) ;\n",
        "  \n",
        "    matmul_basique<<<DimGrid, DimBlock>>>(gpu_A, gpu_B, gpu_C, nbLigneA, nbLigneB, nbColA, nbColB);\n",
        "  \n",
        "    cudaEventRecord(stop) ;\n",
        "    cudaEventSynchronize(stop) ; //Garantit que l’événement s’est exécuté \n",
        "    cudaEventElapsedTime(&tmp_timer, start, stop) ;\n",
        "    milliseconds += tmp_timer;\n",
        "  }\n",
        " \n",
        "  printf(\"Average time over %i iterations for basic matrix mutliplication with TILE_WIDTH = %i : %f ms\", nIter, TILE_WIDTH, milliseconds/nIter);\n",
        "  \n",
        "  /* Copie de gpu_C du GPU sur le CPU */\n",
        "  cudaMemcpy(C, gpu_C, nbLigneA * nbColB * sizeof(float), cudaMemcpyDeviceToHost) ;\n",
        " \n",
        "  /* Vérification du résultat*/\n",
        "  float maxError = 0.0f;\n",
        "  for (int i = 0; i < nbLigneA * nbColB; i++){\n",
        "      maxError = max(maxError, abs(C[i]- 2*nbLigneB));\n",
        "  }\n",
        "  printf(\"\\nMax error: %f\\n\", maxError);\n",
        " \n",
        "  if(maxError == 0)\n",
        "    printf(\"No errors in the computations of the multiplication !\");\n",
        "\n",
        "  /* Libération de la mémoire sur le GPU*/ \n",
        "  cudaFree(gpu_A);\n",
        "  cudaFree(gpu_B);\n",
        "  cudaFree(gpu_C);\n",
        "\n",
        "  /* Libération de la mémoire sur le CPU*/\n",
        "  free(A);\n",
        "  free(B);\n",
        "  free(C);\n",
        "}"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average time over 100 iterations for basic matrix mutliplication with TILE_WIDTH = 16 : 0.287865 ms\n",
            "Max error: 0.000000\n",
            "No errors in the computations of the multiplication !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDYPhswTIHao",
        "colab_type": "text"
      },
      "source": [
        "## Tiled Matrix multiplication"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxMRtRX5IPl1",
        "colab_type": "text"
      },
      "source": [
        "### TILE_WIDTH = 32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmGM6gaDIVwx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "cd517b44-d0b3-4547-deb9-b9f1e9c0decc"
      },
      "source": [
        "%%cu\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "#include <cublas_v2.h>\n",
        "\n",
        "#define TILE_WIDTH 32\n",
        "#define SIZE 20\n",
        "/********************** kernel **************************/\n",
        "__global__\n",
        "void matmul_tuile(float *A, float *B, float *C, int nb_ColA, int nb_ColB, int nb_LigneA, int nb_LigneB)\n",
        "{\n",
        "  int row = blockIdx.y*blockDim.y+threadIdx.y;\n",
        "  int col = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "  //Memoire partagée pour le tuilage\n",
        "  __shared__ float A_shared[TILE_WIDTH][TILE_WIDTH];\n",
        "  __shared__ float B_shared[TILE_WIDTH][TILE_WIDTH];\n",
        "  //Resultats temporaires\n",
        "  float product_val = 0;\n",
        " \n",
        "  //Rempli la mémoire partagée\n",
        "  for(int k=0; k < (TILE_WIDTH + nb_ColA - 1)/TILE_WIDTH; k++) {\n",
        "    //A : tuilage ligne\n",
        "    if (k*TILE_WIDTH + threadIdx.x < nb_ColA && row < nb_LigneA)\n",
        "      A_shared[threadIdx.y][threadIdx.x] = A[row*nb_ColA + k*TILE_WIDTH + threadIdx.x];\n",
        "    else\n",
        "      A_shared[threadIdx.y][threadIdx.x] = 0.0;\n",
        "\n",
        "    //B : tuilage colonne\n",
        "    if (k*TILE_WIDTH + threadIdx.y < nb_LigneB && col < nb_ColB)\n",
        "      B_shared[threadIdx.y][threadIdx.x] = B[(k*TILE_WIDTH + threadIdx.y)*nb_ColB + col];\n",
        "    else\n",
        "      B_shared[threadIdx.y][threadIdx.x] = 0.0;\n",
        "\n",
        "    //Synchronisation des threads dans chaque bloc\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int n = 0; n < TILE_WIDTH; ++n)\n",
        "      product_val += A_shared[threadIdx.y][n] * B_shared[n][threadIdx.x];\n",
        "\n",
        "    //Synchronisation des threads dans chaque bloc\n",
        "     __syncthreads();\n",
        "    }\n",
        "      \n",
        "  //Ecriture du résultat dans C\n",
        "  if(row < nb_ColA && col < nb_LigneA){\n",
        "    C[((blockIdx.y * blockDim.y + threadIdx.y)*nb_ColA) + (blockIdx.x * blockDim.x)+ threadIdx.x] = product_val;\n",
        "  }\n",
        "\n",
        "}\n",
        "\n",
        "/********************** Host functions **************************/\n",
        "\n",
        "/*For debugging purpose*/\n",
        "void affiche_tab(char *chaine, float *tab, int len){\n",
        "   int k;\n",
        "   printf(\"\\nLes 10 premiers de %s: \\n\",chaine);\n",
        "   for (k=0; k<10; k++) \n",
        "      printf(\"%.2f \",tab[k]);\n",
        "   printf(\"\\nLes 10 derniers: \\n\");\n",
        "   for (k=0; k<len; k++){\n",
        "       if(tab[k] == 0){\n",
        "           printf(\"%i \", k);\n",
        "           break;\n",
        "       }\n",
        "   } \n",
        "   printf(\"\\n\");\n",
        "}\n",
        "\n",
        "/********************** main **************************/\n",
        "int main(void)\n",
        "{\n",
        "  float *A, *B, *C, *gpu_A, *gpu_B, *gpu_C;\n",
        "  int nbLigneA, nbLigneB, nbColA, nbColB;\n",
        "  float milliseconds = 0.0;\n",
        "  cudaEvent_t start, stop ;\n",
        "  int nIter = 100;\n",
        "  \n",
        "  nbLigneA = TILE_WIDTH * SIZE;\n",
        "  nbLigneB = TILE_WIDTH * SIZE;\n",
        "  nbColA = TILE_WIDTH * SIZE;\n",
        "  nbColB = TILE_WIDTH * SIZE;\n",
        "\n",
        "  dim3 DimGrid(SIZE, SIZE, 1);\n",
        "  dim3 DimBlock(TILE_WIDTH, TILE_WIDTH, 1);\n",
        " \n",
        "  A = (float*) malloc(nbLigneA * nbColA * sizeof(float));\n",
        "  B = (float*) malloc(nbLigneB * nbColB * sizeof(float));\n",
        "  C = (float*) malloc(nbLigneA * nbColB * sizeof(float));\n",
        "\n",
        "  /*Allocation de l'espace pour le GPU */\n",
        "  cudaMalloc((void**) &gpu_A, nbLigneA * nbColA * sizeof(float));\n",
        "  cudaMalloc((void**) &gpu_B, nbLigneB * nbColB * sizeof(float));\n",
        "  cudaMalloc((void**) &gpu_C, nbLigneA * nbColB * sizeof(float));  \n",
        " \n",
        "  /* Initialisation de A et B*/\n",
        "  for (int i = 0; i < nbLigneA * nbColA; i++) {\n",
        "    A[i] = 1.0;\n",
        "  }\n",
        "\n",
        "  for (int i = 0; i < nbLigneB * nbColB; i++) {\n",
        "    B[i] = 2.0;\n",
        "  }\n",
        "\n",
        " /* Copie de gpu_A et gpu_B sur le GPU */\n",
        "  cudaMemcpy(gpu_A, A, nbLigneA * nbColA * sizeof(float), cudaMemcpyHostToDevice) ;\n",
        "  cudaMemcpy(gpu_B, B, nbLigneB * nbColB * sizeof(float), cudaMemcpyHostToDevice) ;\n",
        "  \n",
        "/* Moyenne du temps d'exécution de la multiplication de matrice avec algo tuilé */\n",
        "  for(int i=0; i<nIter; i++){\n",
        "    float tmp_timer = 0.0;\n",
        "    /* Lancement du kernel avec mesure du temps */\n",
        "    cudaEventCreate(&start) ; cudaEventCreate(&stop) ;\n",
        "    cudaEventRecord(start) ;\n",
        "  \n",
        "    matmul_tuile<<<DimGrid, DimBlock>>>(gpu_A, gpu_B, gpu_C, nbLigneA, nbLigneB, nbColA, nbColB);\n",
        "  \n",
        "    cudaEventRecord(stop) ;\n",
        "    cudaEventSynchronize(stop) ; //Garantit que l’événement s’est exécuté \n",
        "    cudaEventElapsedTime(&tmp_timer, start, stop) ;\n",
        "    milliseconds += tmp_timer;\n",
        "  }\n",
        " \n",
        "  printf(\"Average time over %i iterations for tiled matrix mutliplication with TILE_WIDTH = %i : %f ms\", nIter, TILE_WIDTH, milliseconds/nIter);\n",
        "  \n",
        "  /* Copie de gpu_C du GPU sur le CPU */\n",
        "  cudaMemcpy(C, gpu_C, nbLigneA * nbColB * sizeof(float), cudaMemcpyDeviceToHost) ;\n",
        " \n",
        "  /* Vérification du résultat*/\n",
        "  float maxError = 0.0f;\n",
        "  for (int i = 0; i < nbLigneA * nbColB; i++){\n",
        "      maxError = max(maxError, abs(C[i]- 2*nbLigneB));\n",
        "  }\n",
        "  printf(\"\\nMax error: %f\\n\", maxError);\n",
        " \n",
        "  if(maxError == 0)\n",
        "    printf(\"No errors in the computations of the multiplication !\");\n",
        "\n",
        "  /* Libération de la mémoire sur le GPU*/ \n",
        "  cudaFree(gpu_A);\n",
        "  cudaFree(gpu_B);\n",
        "  cudaFree(gpu_C);\n",
        "\n",
        "  /* Libération de la mémoire sur le CPU*/\n",
        "  free(A);\n",
        "  free(B);\n",
        "  free(C);\n",
        "}\n"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average time over 100 iterations for tiled matrix mutliplication with TILE_WIDTH = 32 : 1.298433 ms\n",
            "Max error: 0.000000\n",
            "No errors in the computations of the multiplication !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPsb7v8GIPof",
        "colab_type": "text"
      },
      "source": [
        "### TILE_WIDTH = 16"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-6DifrCZIWSq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e6082d30-7e9c-4d1f-d854-412a37bdaf18"
      },
      "source": [
        "%%cu\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "#include <cublas_v2.h>\n",
        "\n",
        "#define TILE_WIDTH 16\n",
        "#define SIZE 20\n",
        "/********************** kernel **************************/\n",
        "__global__\n",
        "void matmul_tuile(float *A, float *B, float *C, int nb_ColA, int nb_ColB, int nb_LigneA, int nb_LigneB)\n",
        "{\n",
        "  int row = blockIdx.y*blockDim.y+threadIdx.y;\n",
        "  int col = blockIdx.x*blockDim.x+threadIdx.x;\n",
        "  //Memoire partagée pour le tuilage\n",
        "  __shared__ float A_shared[TILE_WIDTH][TILE_WIDTH];\n",
        "  __shared__ float B_shared[TILE_WIDTH][TILE_WIDTH];\n",
        "  //Resultats temporaires\n",
        "  float product_val = 0;\n",
        " \n",
        "  //Rempli la mémoire partagée\n",
        "  for(int k=0; k < (TILE_WIDTH + nb_ColA - 1)/TILE_WIDTH; k++) {\n",
        "    //A : tuilage ligne\n",
        "    if (k*TILE_WIDTH + threadIdx.x < nb_ColA && row < nb_LigneA)\n",
        "      A_shared[threadIdx.y][threadIdx.x] = A[row*nb_ColA + k*TILE_WIDTH + threadIdx.x];\n",
        "    else\n",
        "      A_shared[threadIdx.y][threadIdx.x] = 0.0;\n",
        "\n",
        "    //B : tuilage colonne\n",
        "    if (k*TILE_WIDTH + threadIdx.y < nb_LigneB && col < nb_ColB)\n",
        "      B_shared[threadIdx.y][threadIdx.x] = B[(k*TILE_WIDTH + threadIdx.y)*nb_ColB + col];\n",
        "    else\n",
        "      B_shared[threadIdx.y][threadIdx.x] = 0.0;\n",
        "\n",
        "    //Synchronisation des threads dans chaque bloc\n",
        "    __syncthreads();\n",
        "\n",
        "    for (int n = 0; n < TILE_WIDTH; ++n)\n",
        "      product_val += A_shared[threadIdx.y][n] * B_shared[n][threadIdx.x];\n",
        "\n",
        "    //Synchronisation des threads dans chaque bloc\n",
        "     __syncthreads();\n",
        "    }\n",
        "      \n",
        "  //Ecriture du résultat dans C\n",
        "  if(row < nb_ColA && col < nb_LigneA){\n",
        "    C[((blockIdx.y * blockDim.y + threadIdx.y)*nb_ColA) + (blockIdx.x * blockDim.x)+ threadIdx.x] = product_val;\n",
        "  }\n",
        "\n",
        "}\n",
        "\n",
        "/********************** Host functions **************************/\n",
        "\n",
        "/*For debugging purpose*/\n",
        "void affiche_tab(char *chaine, float *tab, int len){\n",
        "   int k;\n",
        "   printf(\"\\nLes 10 premiers de %s: \\n\",chaine);\n",
        "   for (k=0; k<10; k++) \n",
        "      printf(\"%.2f \",tab[k]);\n",
        "   printf(\"\\nLes 10 derniers: \\n\");\n",
        "   for (k=0; k<len; k++){\n",
        "       if(tab[k] == 0){\n",
        "           printf(\"%i \", k);\n",
        "           break;\n",
        "       }\n",
        "   } \n",
        "   printf(\"\\n\");\n",
        "}\n",
        "\n",
        "/********************** main **************************/\n",
        "int main(void)\n",
        "{\n",
        "  float *A, *B, *C, *gpu_A, *gpu_B, *gpu_C;\n",
        "  int nbLigneA, nbLigneB, nbColA, nbColB;\n",
        "  float milliseconds = 0.0;\n",
        "  cudaEvent_t start, stop ;\n",
        "  int nIter = 100;\n",
        "  \n",
        "  nbLigneA = TILE_WIDTH * SIZE;\n",
        "  nbLigneB = TILE_WIDTH * SIZE;\n",
        "  nbColA = TILE_WIDTH * SIZE;\n",
        "  nbColB = TILE_WIDTH * SIZE;\n",
        "\n",
        "  dim3 DimGrid(SIZE, SIZE, 1);\n",
        "  dim3 DimBlock(TILE_WIDTH, TILE_WIDTH, 1);\n",
        " \n",
        "  A = (float*) malloc(nbLigneA * nbColA * sizeof(float));\n",
        "  B = (float*) malloc(nbLigneB * nbColB * sizeof(float));\n",
        "  C = (float*) malloc(nbLigneA * nbColB * sizeof(float));\n",
        "\n",
        "  /*Allocation de l'espace pour le GPU */\n",
        "  cudaMalloc((void**) &gpu_A, nbLigneA * nbColA * sizeof(float));\n",
        "  cudaMalloc((void**) &gpu_B, nbLigneB * nbColB * sizeof(float));\n",
        "  cudaMalloc((void**) &gpu_C, nbLigneA * nbColB * sizeof(float));  \n",
        " \n",
        "  /* Initialisation de A et B*/\n",
        "  for (int i = 0; i < nbLigneA * nbColA; i++) {\n",
        "    A[i] = 1.0;\n",
        "  }\n",
        "\n",
        "  for (int i = 0; i < nbLigneB * nbColB; i++) {\n",
        "    B[i] = 2.0;\n",
        "  }\n",
        "\n",
        " /* Copie de gpu_A et gpu_B sur le GPU */\n",
        "  cudaMemcpy(gpu_A, A, nbLigneA * nbColA * sizeof(float), cudaMemcpyHostToDevice) ;\n",
        "  cudaMemcpy(gpu_B, B, nbLigneB * nbColB * sizeof(float), cudaMemcpyHostToDevice) ;\n",
        "  \n",
        "/* Moyenne du temps d'exécution de la multiplication de matrice avec algo tuilé */\n",
        "  for(int i=0; i<nIter; i++){\n",
        "    float tmp_timer = 0.0;\n",
        "    /* Lancement du kernel avec mesure du temps */\n",
        "    cudaEventCreate(&start) ; cudaEventCreate(&stop) ;\n",
        "    cudaEventRecord(start) ;\n",
        "  \n",
        "    matmul_tuile<<<DimGrid, DimBlock>>>(gpu_A, gpu_B, gpu_C, nbLigneA, nbLigneB, nbColA, nbColB);\n",
        "  \n",
        "    cudaEventRecord(stop) ;\n",
        "    cudaEventSynchronize(stop) ; //Garantit que l’événement s’est exécuté \n",
        "    cudaEventElapsedTime(&tmp_timer, start, stop) ;\n",
        "    milliseconds += tmp_timer;\n",
        "  }\n",
        " \n",
        "  printf(\"Average time over %i iterations for tiled matrix mutliplication with TILE_WIDTH = %i : %f ms\", nIter, TILE_WIDTH, milliseconds/nIter);\n",
        "  \n",
        "  /* Copie de gpu_C du GPU sur le CPU */\n",
        "  cudaMemcpy(C, gpu_C, nbLigneA * nbColB * sizeof(float), cudaMemcpyDeviceToHost) ;\n",
        " \n",
        "  /* Vérification du résultat*/\n",
        "  float maxError = 0.0f;\n",
        "  for (int i = 0; i < nbLigneA * nbColB; i++){\n",
        "      maxError = max(maxError, abs(C[i]- 2*nbLigneB));\n",
        "  }\n",
        "  printf(\"\\nMax error: %f\\n\", maxError);\n",
        " \n",
        "  if(maxError == 0)\n",
        "    printf(\"No errors in the computations of the multiplication !\");\n",
        "\n",
        "  /* Libération de la mémoire sur le GPU*/ \n",
        "  cudaFree(gpu_A);\n",
        "  cudaFree(gpu_B);\n",
        "  cudaFree(gpu_C);\n",
        "\n",
        "  /* Libération de la mémoire sur le CPU*/\n",
        "  free(A);\n",
        "  free(B);\n",
        "  free(C);\n",
        "}"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average time over 100 iterations for tiled matrix mutliplication with TILE_WIDTH = 16 : 0.198777 ms\n",
            "Max error: 0.000000\n",
            "No errors in the computations of the multiplication !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrs694b4FmJ4",
        "colab_type": "text"
      },
      "source": [
        "## Matrix multiplication with built-in from CUDA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOxvzphXFvt6",
        "colab_type": "text"
      },
      "source": [
        "### TILE_WIDTH = 32"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRVxmBknF5SK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "09796eb4-e9be-499e-eb20-d413346e2a68"
      },
      "source": [
        "%%cu\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "#include <cublas_v2.h>\n",
        "\n",
        "#define TILE_WIDTH 32\n",
        "#define SIZE 20\n",
        "/********************** kernel **************************/\n",
        "\n",
        "/********************** Host functions **************************/\n",
        "\n",
        "/*For debugging purpose */\n",
        "void affiche_tab(char *chaine, float *tab, int len){\n",
        "   int k;\n",
        "   printf(\"\\nLes 10 premiers de %s: \\n\",chaine);\n",
        "   for (k=0; k<10; k++) \n",
        "      printf(\"%.2f \",tab[k]);\n",
        "   printf(\"\\nLes 10 derniers: \\n\");\n",
        "   for (k=0; k<len; k++){\n",
        "       if(tab[k] == 0){\n",
        "           printf(\"%i \", k);\n",
        "           break;\n",
        "       }\n",
        "   } \n",
        "   printf(\"\\n\");\n",
        "}\n",
        "\n",
        "// Multiply the arrays A and B on GPU and save the result in C\n",
        "// C(m,n) = A(m,k) * B(k,n)\n",
        "void gpu_blas_mmul(cublasHandle_t &handle, const float *A, const float *B, float *C, const int m, const int k, const int n) {\n",
        "  int lda=m,ldb=k,ldc=m;\n",
        "  const float alf = 1;\n",
        "  const float bet = 0;\n",
        "  const float *alpha = &alf;\n",
        "  const float *beta = &bet;\n",
        " \n",
        "  // Do the actual multiplication\n",
        "  cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N, m, n, k, alpha, A, lda, B, ldb, beta, C, ldc);\n",
        "\n",
        "}\n",
        "\n",
        "/********************** main **************************/\n",
        "int main(void)\n",
        "{\n",
        "  float *A, *B, *C, *gpu_A, *gpu_B, *gpu_C;\n",
        "  int nbLigneA, nbLigneB, nbColA, nbColB;\n",
        "  float milliseconds = 0.0;\n",
        "  cudaEvent_t start, stop ;\n",
        "  int nIter = 100;\n",
        "  \n",
        "  nbLigneA = TILE_WIDTH * SIZE;\n",
        "  nbLigneB = TILE_WIDTH * SIZE;\n",
        "  nbColA = TILE_WIDTH * SIZE;\n",
        "  nbColB = TILE_WIDTH * SIZE;\n",
        " \n",
        "  A = (float*) malloc(nbLigneA * nbColA * sizeof(float));\n",
        "  B = (float*) malloc(nbLigneB * nbColB * sizeof(float));\n",
        "  C = (float*) malloc(nbLigneA * nbColB * sizeof(float));\n",
        "\n",
        "  /*Allocation de l'espace pour le GPU */\n",
        "  cudaMalloc((void**) &gpu_A, nbLigneA * nbColA * sizeof(float));\n",
        "  cudaMalloc((void**) &gpu_B, nbLigneB * nbColB * sizeof(float));\n",
        "  cudaMalloc((void**) &gpu_C, nbLigneA * nbColB * sizeof(float));  \n",
        " \n",
        "  /* Initialisation de A et B*/\n",
        "  for (int i = 0; i < nbLigneA * nbColA; i++) {\n",
        "    A[i] = 1.0;\n",
        "  }\n",
        "\n",
        "  for (int i = 0; i < nbLigneB * nbColB; i++) {\n",
        "    B[i] = 2.0;\n",
        "  }\n",
        "\n",
        " /* Copie de gpu_A et gpu_B sur le GPU */\n",
        "  cudaMemcpy(gpu_A, A, nbLigneA * nbColA * sizeof(float), cudaMemcpyHostToDevice) ;\n",
        "  cudaMemcpy(gpu_B, B, nbLigneB * nbColB * sizeof(float), cudaMemcpyHostToDevice) ;\n",
        "  \n",
        "  /* Moyenne du temps d'exécution de la multiplication de matrice avec cublasSgemm*/\n",
        "  for(int i=0; i<nIter; i++){\n",
        "    float tmp_timer = 0.0;\n",
        "    // Create a handle for CUBLAS\n",
        "    cublasHandle_t handle;\n",
        "    cublasCreate(&handle);\n",
        "\n",
        "    /* Lancement du kernel avec mesure du temps */\n",
        "    cudaEventCreate(&start) ; cudaEventCreate(&stop) ;\n",
        "    cudaEventRecord(start) ;\n",
        "  \n",
        "    gpu_blas_mmul(handle, gpu_A, gpu_B, gpu_C, nbLigneA, nbColA, nbColB);\n",
        "\n",
        "    cudaEventRecord(stop) ;\n",
        "    cudaEventSynchronize(stop) ; //Garantit que l’événement s’est exécuté \n",
        "    cudaEventElapsedTime(&tmp_timer, start, stop) ;\n",
        "    milliseconds += tmp_timer;\n",
        "    // Destroy the handle\n",
        "    cublasDestroy(handle);\n",
        "\n",
        "  }\n",
        " \n",
        "  printf(\"Average time over %i iterations for CUDA matrix mutliplication with TILE_WIDTH = %i : %f ms\", nIter, TILE_WIDTH, milliseconds/nIter);\n",
        "  /* Copie de gpu_C du GPU sur le CPU */\n",
        "  cudaMemcpy(C, gpu_C, nbLigneA * nbColB * sizeof(float), cudaMemcpyDeviceToHost) ;\n",
        " \n",
        "  /* Vérification du résultat*/\n",
        "  float maxError = 0.0f;\n",
        "  for (int i = 0; i < nbLigneA * nbColB; i++){\n",
        "      maxError = max(maxError, abs(C[i]- 2*nbLigneB));\n",
        "  }\n",
        "  printf(\"\\nMax error: %f\\n\", maxError);\n",
        " \n",
        "  if(maxError == 0)\n",
        "    printf(\"No errors in the computations of the multiplication !\");\n",
        "\n",
        "  /* Libération de la mémoire sur le GPU*/ \n",
        "  cudaFree(gpu_A);\n",
        "  cudaFree(gpu_B);\n",
        "  cudaFree(gpu_C);\n",
        "\n",
        "  /* Libération de la mémoire sur le CPU*/\n",
        "  free(A);\n",
        "  free(B);\n",
        "  free(C);\n",
        "}"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average time over 100 iterations for CUDA matrix mutliplication with TILE_WIDTH = 32 : 0.261049 ms\n",
            "Max error: 0.000000\n",
            "No errors in the computations of the multiplication !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TmfA56k6GbSZ",
        "colab_type": "text"
      },
      "source": [
        "### TILE_WIDTH = 16\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbTvP_-0GfUS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f32b2601-33dd-4319-fb9e-39360e83df0f"
      },
      "source": [
        "%%cu\n",
        "#include <stdlib.h>\n",
        "#include <stdio.h>\n",
        "\n",
        "#include <cuda.h>\n",
        "#include <cuda_runtime.h>\n",
        "#include <helper_cuda.h>\n",
        "#include <cublas_v2.h>\n",
        "\n",
        "#define TILE_WIDTH 16\n",
        "#define SIZE 20\n",
        "/********************** kernel **************************/\n",
        "\n",
        "/********************** Host functions **************************/\n",
        "\n",
        "void affiche_tab(char *chaine, float *tab, int len){\n",
        "   int k;\n",
        "   printf(\"\\nLes 10 premiers de %s: \\n\",chaine);\n",
        "   for (k=0; k<10; k++) \n",
        "      printf(\"%.2f \",tab[k]);\n",
        "   printf(\"\\nLes 10 derniers: \\n\");\n",
        "   for (k=0; k<len; k++){\n",
        "       if(tab[k] == 0){\n",
        "           printf(\"%i \", k);\n",
        "           break;\n",
        "       }\n",
        "   } \n",
        "   printf(\"\\n\");\n",
        "}\n",
        "\n",
        "// Multiply the arrays A and B on GPU and save the result in C\n",
        "// C(m,n) = A(m,k) * B(k,n)\n",
        "void gpu_blas_mmul(cublasHandle_t &handle, const float *A, const float *B, float *C, const int m, const int k, const int n) {\n",
        "  int lda=m,ldb=k,ldc=m;\n",
        "  const float alf = 1;\n",
        "  const float bet = 0;\n",
        "  const float *alpha = &alf;\n",
        "  const float *beta = &bet;\n",
        " \n",
        "  // Do the actual multiplication\n",
        "  cublasSgemm(handle, CUBLAS_OP_N, CUBLAS_OP_N, m, n, k, alpha, A, lda, B, ldb, beta, C, ldc);\n",
        "\n",
        "}\n",
        "\n",
        "/********************** main **************************/\n",
        "int main(void)\n",
        "{\n",
        "  float *A, *B, *C, *gpu_A, *gpu_B, *gpu_C;\n",
        "  int nbLigneA, nbLigneB, nbColA, nbColB;\n",
        "  float milliseconds = 0.0;\n",
        "  cudaEvent_t start, stop ;\n",
        "  int nIter = 100;\n",
        "  \n",
        "  nbLigneA = TILE_WIDTH * SIZE;\n",
        "  nbLigneB = TILE_WIDTH * SIZE;\n",
        "  nbColA = TILE_WIDTH * SIZE;\n",
        "  nbColB = TILE_WIDTH * SIZE;\n",
        " \n",
        "  A = (float*) malloc(nbLigneA * nbColA * sizeof(float));\n",
        "  B = (float*) malloc(nbLigneB * nbColB * sizeof(float));\n",
        "  C = (float*) malloc(nbLigneA * nbColB * sizeof(float));\n",
        "\n",
        "  /*Allocation de l'espace pour le GPU */\n",
        "  cudaMalloc((void**) &gpu_A, nbLigneA * nbColA * sizeof(float));\n",
        "  cudaMalloc((void**) &gpu_B, nbLigneB * nbColB * sizeof(float));\n",
        "  cudaMalloc((void**) &gpu_C, nbLigneA * nbColB * sizeof(float));  \n",
        " \n",
        "  /* Initialisation de A et B*/\n",
        "  for (int i = 0; i < nbLigneA * nbColA; i++) {\n",
        "    A[i] = 1.0;\n",
        "  }\n",
        "\n",
        "  for (int i = 0; i < nbLigneB * nbColB; i++) {\n",
        "    B[i] = 2.0;\n",
        "  }\n",
        "\n",
        " /* Copie de gpu_A et gpu_B sur le GPU */\n",
        "  cudaMemcpy(gpu_A, A, nbLigneA * nbColA * sizeof(float), cudaMemcpyHostToDevice) ;\n",
        "  cudaMemcpy(gpu_B, B, nbLigneB * nbColB * sizeof(float), cudaMemcpyHostToDevice) ;\n",
        "  \n",
        "  /* Moyenne du temps d'exécution de la multiplication de matrice avec cublasSgemm */\n",
        "  for(int i=0; i<nIter; i++){\n",
        "    float tmp_timer = 0.0;\n",
        "    // Create a handle for CUBLAS\n",
        "    cublasHandle_t handle;\n",
        "    cublasCreate(&handle);\n",
        "\n",
        "    /* Lancement du kernel avec mesure du temps */\n",
        "    cudaEventCreate(&start) ; cudaEventCreate(&stop) ;\n",
        "    cudaEventRecord(start) ;\n",
        "  \n",
        "    gpu_blas_mmul(handle, gpu_A, gpu_B, gpu_C, nbLigneA, nbColA, nbColB);\n",
        "\n",
        "    cudaEventRecord(stop) ;\n",
        "    cudaEventSynchronize(stop) ; //Garantit que l’événement s’est exécuté \n",
        "    cudaEventElapsedTime(&tmp_timer, start, stop) ;\n",
        "    milliseconds += tmp_timer;\n",
        "    // Destroy the handle\n",
        "    cublasDestroy(handle);\n",
        "\n",
        "  }\n",
        " \n",
        "  printf(\"Average time over %i iterations for CUDA matrix mutliplication with TILE_WIDTH = %i : %f ms\", nIter, TILE_WIDTH, milliseconds/nIter);\n",
        "  /* Copie de gpu_C du GPU sur le CPU */\n",
        "  cudaMemcpy(C, gpu_C, nbLigneA * nbColB * sizeof(float), cudaMemcpyDeviceToHost) ;\n",
        " \n",
        "  /* Vérification du résultat*/\n",
        "  float maxError = 0.0f;\n",
        "  for (int i = 0; i < nbLigneA * nbColB; i++){\n",
        "      maxError = max(maxError, abs(C[i]- 2*nbLigneB));\n",
        "  }\n",
        "  printf(\"\\nMax error: %f\\n\", maxError);\n",
        " \n",
        "  if(maxError == 0)\n",
        "    printf(\"No errors in the computations of the multiplication !\");\n",
        "\n",
        "  /* Libération de la mémoire sur le GPU*/ \n",
        "  cudaFree(gpu_A);\n",
        "  cudaFree(gpu_B);\n",
        "  cudaFree(gpu_C);\n",
        "\n",
        "  /* Libération de la mémoire sur le CPU*/\n",
        "  free(A);\n",
        "  free(B);\n",
        "  free(C);\n",
        "}"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Average time over 100 iterations for CUDA matrix mutliplication with TILE_WIDTH = 16 : 0.065900 ms\n",
            "Max error: 0.000000\n",
            "No errors in the computations of the multiplication !\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwKRuVpxP4Ci",
        "colab_type": "text"
      },
      "source": [
        "## Comparison of results and analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-rTXFDWfQAoM",
        "colab_type": "text"
      },
      "source": [
        "Here is the summary of the average computation time over 100 iterations for the 3 different methods of matrix multiplication:\n",
        "\n",
        " Time (ms)  | Basic MM | Tiled MM | cublasSgemm MM\n",
        "--- | --- | --- | ---\n",
        "TILE_WIDTH = 16 | 0.288 | 0.199 | 0.066\n",
        "TILE_WIDTH = 32 | 1.548 | 1.299 | 0.261"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qtr3t6diSS2T",
        "colab_type": "text"
      },
      "source": [
        "* As expected, the basic matrix multiplaction is slower than the tiled version of matrix multiplation. As seen in the slides, this is due to the fact that in the basic matrix multiplication, the access to the data is non aligned and sparse. Moreover, this algorithm isn't efficient because we access several times to the same data in the different matrices A and B.\n",
        "\n",
        "* The tiled multiplication matrix use the shared memory capability of GPU in order to solve this problem. Thanks to the shared memory, we only access once the data by synchronizing every threads within a block. In fact, the performances are much better than the basic multiplication matrix.\n",
        "\n",
        "* Finally we compared the average computation time with the built-in function cublasSgemm from cuBLAS. This library is over optimized and perform the best computation time. This function should implement a tiled algorithm, but it certainly use more optimizations.\n",
        "\n",
        "* I can't precisely explain why a smaller tile width gives a better performance. Maybe this is due to bank conflicts."
      ]
    }
  ]
}